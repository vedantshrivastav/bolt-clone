"use strict";
// Upload file to server using /files API
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.upload = exports.check_jsonl = exports.check_parquet = exports.check_file = void 0;
const core = __importStar(require("../core.js"));
const axios_1 = require("axios");
const fs_1 = __importDefault(require("fs"));
const node_fetch_1 = __importDefault(require("node-fetch"));
const path = __importStar(require("path"));
const progress_stream_1 = __importDefault(require("progress-stream"));
const readline_1 = __importDefault(require("readline"));
const parquetjs_1 = __importDefault(require("parquetjs"));
const { ParquetReader } = parquetjs_1.default;
const failedUploadMessage = {
    message: 'failed to upload file',
};
const baseURL = 'https://api.together.xyz/v1';
const MAX_FILE_SIZE = 4.8; // GB
const BYTES_PER_GB = 1024 * 1024 * 1024;
const MIN_SAMPLES = 1;
const PARQUET_EXPECTED_COLUMNS = ['input_ids', 'attention_mask', 'labels'];
async function check_file(fileName) {
    const stat = fs_1.default.statSync(fileName);
    if (stat.size == 0) {
        return { success: false, message: `File is empty` };
    }
    if (stat.size > MAX_FILE_SIZE * BYTES_PER_GB) {
        return { success: false, message: `File size exceeds the limit of ${MAX_FILE_SIZE} GB` };
    }
    const fileType = path.extname(fileName);
    if (fileType !== '.jsonl' && fileType !== '.parquet') {
        return {
            success: false,
            message: 'File type must be either .jsonl or .parquet',
        };
    }
    if (fileType == '.jsonl') {
        const jsonlCheck = await check_jsonl(fileName);
        if (jsonlCheck) {
            return { success: false, message: jsonlCheck };
        }
    }
    if (fileType == '.parquet') {
        const parquetCheck = await check_parquet(fileName);
        if (parquetCheck) {
            return { success: false, message: parquetCheck };
        }
    }
    return { success: true };
}
exports.check_file = check_file;
async function check_parquet(fileName) {
    try {
        const reader = await ParquetReader.openFile(fileName);
        const cursor = reader.getCursor();
        let record = null;
        const fieldNames = Object.keys(reader.schema.fields);
        if (!('input_ids' in fieldNames)) {
            return `Parquet file ${fileName} does not contain the 'input_ids' column.`;
        }
        for (const fieldName in fieldNames) {
            if (!PARQUET_EXPECTED_COLUMNS.includes(fieldName)) {
                return `Parquet file ${fileName} contains unexpected column ${fieldName}. Only ${PARQUET_EXPECTED_COLUMNS.join(', ')} are supported`;
            }
        }
        const numRows = reader.getRowCount();
        if (numRows < MIN_SAMPLES) {
            return `Parquet file ${fileName} contains only ${numRows} samples. Minimum of ${MIN_SAMPLES} samples are required`;
        }
        await reader.close();
    }
    catch (err) {
        return `failed to read parquet file ${fileName}`;
    }
    return undefined;
}
exports.check_parquet = check_parquet;
// return undefined if the file is valid, otherwise return an error message
async function check_jsonl(fileName) {
    const fileStream = fs_1.default.createReadStream(fileName);
    const rl = readline_1.default.createInterface({
        input: fileStream,
        crlfDelay: Infinity,
    });
    let errors = [];
    let lineNumber = 1;
    for await (const line of rl) {
        try {
            // do not proceed if there are too many errors
            if (errors.length > 20) {
                break;
            }
            const parsedLine = JSON.parse(line);
            if (typeof parsedLine !== 'object') {
                errors.push(`Line number ${lineNumber} is not a valid JSON object`);
                continue;
            }
            const isTextFormat = 'text' in parsedLine;
            const isMessagesFormat = 'messages' in parsedLine;
            if (!isTextFormat && !isMessagesFormat) {
                errors.push(`Invalid format found on line ${lineNumber} of the the input file. Expected format: {'text': 'my sample string'} or {'messages': [{role: 'role', content: 'content'}]}.`);
                continue;
            }
            if (isTextFormat && typeof parsedLine['text'] !== 'string') {
                errors.push(`'Invalid value type for "text" key on line ${lineNumber}. Expected string`);
                continue;
            }
            if (isMessagesFormat) {
                const firstMessage = parsedLine['messages'][0];
                // console.log({ firstMessage });
                const firstLineHasRole = typeof firstMessage['role'] === 'string';
                const firstLineHasContent = typeof firstMessage['content'] === 'string';
                if (!firstLineHasRole || !firstLineHasContent) {
                    errors.push(`Invalid format found on line ${lineNumber} of the the input file. Expected format: {'messages': [{role: 'role', content: 'content'}]}.`);
                    continue;
                }
            }
        }
        catch (error) {
            errors.push(`Error parsing line number ${lineNumber}`);
        }
        lineNumber += 1;
    }
    lineNumber -= 1;
    if (lineNumber < MIN_SAMPLES) {
        errors.push(`Processing ${fileName} resulted in only ${lineNumber - 1} samples.`);
    }
    if (errors.length > 0) {
        return errors.join('\n');
    }
    return undefined;
}
exports.check_jsonl = check_jsonl;
async function upload(fileName, check = true) {
    let purpose = 'fine-tune';
    if (!fs_1.default.existsSync(fileName)) {
        return {
            message: 'File does not exists',
        };
    }
    const fileType = path.extname(fileName);
    if (fileType !== '.jsonl' && fileType !== '.parquet') {
        return {
            message: 'File type must be either .jsonl or .parquet',
        };
    }
    if (check) {
        const checkFile = await check_file(fileName);
        if (!checkFile.success) {
            return {
                message: checkFile.message || `verification of ${fileName} failed with some unknown reason`,
            };
        }
    }
    // steps to do
    // 1. check if file exists
    // 2. get signed upload url
    // 3. upload file
    const baseUrl = core.readEnv('TOGETHER_API_BASE_URL') || 'https://api.together.ai/v1';
    const apiKey = core.readEnv('TOGETHER_API_KEY');
    if (!apiKey) {
        return {
            message: 'API key is required',
        };
    }
    const getSigned = baseURL + '/files';
    try {
        const params = new URLSearchParams({
            file_name: fileName,
            purpose: purpose,
        });
        const fullUrl = `${getSigned}?${params}`;
        const r = await (0, node_fetch_1.default)(fullUrl, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/x-www-form-urlencoded',
                Authorization: `Bearer ${apiKey}`,
            },
            redirect: 'manual',
            body: params.toString(),
        });
        if (r.status !== 302) {
            return failedUploadMessage;
        }
        const uploadUrl = r.headers.get('location') || '';
        if (!uploadUrl || uploadUrl === '') {
            return failedUploadMessage;
        }
        const fileId = r.headers.get('x-together-file-id') || '';
        if (!fileId || fileId === '') {
            return failedUploadMessage;
        }
        const fileStream = fs_1.default.createReadStream(fileName);
        const fileSize = fs_1.default.statSync(fileName).size;
        const progressStream = (0, progress_stream_1.default)({
            length: fileSize,
            time: 100, // Emit progress events every 100ms
        });
        // Listen to progress events and log them
        progressStream.on('progress', (progress) => {
            displayProgress(progress.percentage);
        });
        let uploadedBytes = 0;
        // upload the file to uploadUrl
        const uploadResponse = await (0, node_fetch_1.default)(uploadUrl, {
            method: 'PUT',
            headers: {
                'Content-Type': 'application/octet-stream',
            },
            body: fileStream.pipe(progressStream),
        });
        displayProgress(100);
        process.stdout.write('\n');
        return {
            id: fileId,
            object: 'file',
            type: 'jsonl',
            purpose: 'fine-tune',
            filename: fileName,
            bytes: fileSize,
            line_count: 0,
            processed: true,
        };
    }
    catch (error) {
        if ((0, axios_1.isAxiosError)(error)) {
            // handle axios error here
            if (error.status) {
                return {
                    message: `failed to upload file with status ${error.status}`,
                };
            }
        }
        return {
            message: 'failed to upload file',
        };
    }
}
exports.upload = upload;
async function displayProgress(progress) {
    const barWidth = 40; // Number of characters for the progress bar
    const completedBars = Math.round((progress / 100) * barWidth);
    let remainingBars = barWidth - completedBars;
    if (remainingBars < 0) {
        remainingBars = 0;
    }
    const progressBar = `[${'='.repeat(completedBars)}${' '.repeat(remainingBars)}] ${progress.toFixed(2)}%`;
    // Clear the line and write progress
    //process.stdout.clearLine(0); //clean entire line
    process.stdout.cursorTo(0);
    process.stdout.write(progressBar, () => { });
    await sleep(2000);
}
async function sleep(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
}
//# sourceMappingURL=upload.js.map